/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package com.jnpersson.discount.fastdoop

import org.apache.hadoop.conf.Configuration
import org.apache.hadoop.fs.Path
import org.apache.hadoop.io.Text
import org.apache.hadoop.mapreduce.lib.input.FileSplit
import org.apache.hadoop.mapreduce.{InputSplit, RecordReader, TaskAttemptContext}

import scala.io.Source

/**
 * FAI (fasta index) record.
 *
 * Example entries in a FAI file:
 *
 * ENA|LR865458|LR865458.1 590561804       75      60      61
 * ENA|LR865459|LR865459.1 685720839       600404651       60      61
 * ENA|LR865460|LR865460.1 490910922       1297554246      60      61
 *
 * @param id Sequence ID
 * @param length length in bps
 * @param start start position (byte offset in file)
 * @param bpsPerLine bps per line
 * @param bytesPerLine bytes per line
 */
case class FAIRecord(id: String, length: Long, start: Long, bpsPerLine: Int, bytesPerLine: Int) {
  /** byte offset of the final character in this sequence */
  val end = (start + (length / bpsPerLine) * bytesPerLine + (length % bpsPerLine)) - 1
}

/**
 * FASTA file reader that uses a faidx (.fai) file to track sequence locations.
 * .fai indexes can be generated by various tools, for example seqkit:
 * https://github.com/shenwei356/seqkit/
 *
 * This reader can read a mix of full and partial sequences. If the sequence is fully contained in this split,
 * it will be read as a single [[PartialSequence]] record. Otherwise, it will be read as multiple records.
 * Partial sequences can be identified and reassembled using their header (corresponding to sequence ID)
 * and seqPosition fields.
 *
 * Partial sequences are read together with (k-1) bps from the next part to ensure that full k-mers can be processed.
 *
 * The reader for every split must stream the FAI file. Thus, it is not recommended to use this reader for e.g. short
 * reads, or when the maximum size of a sequence is relatively small.
 * [[ShortReadsRecordReader]] and [[FASTQReadsRecordReader]] are better suited to such a task.
 * For reading a single long sequence without a FAI index, [[LongReadsRecordReader]] can be used instead.
 *
 * @see [[IndexedFastaFormat]]
 *
 * @author Johan NystrÃ¶m-Persson
 *
 * @version 1.0
 */
class IndexedFastaReader extends RecordReader[Text, PartialSequence] {
  //First byte of this split
  private var startByte = 0L

  //Last byte of this split
  private var endByte = 0L

  private var currKey: Text = null

  private var currValue: PartialSequence = null

  private var myInputSplitBuffer = Array[Byte]()

  private var k = 0

  /**
   * FAIRecords corresponding to sequences that we have yet to read
   */
  private var faiRecords: Iterator[FAIRecord] = Iterator.empty
  private var faiSource: Source = null

  private var sizeBuffer1 = 0
  private var sizeBuffer2 = 0

  /**
   * Read a fai file (such as the one generated by 'seqkit faidx') and return the records
   *
   * @param path Path to the fai file
   * @param job
   * @return an iterator with the FAIRecords in this file, in order
   * @throws IOException
   */
  private def readFastaIndex(path: Path, job: Configuration): Iterator[FAIRecord] = {
    val file = path.getFileSystem(job).open(path)
    faiSource = Source.fromInputStream(file)
    faiSource.getLines().map(line => {
      val spl = line.split("\t")
      FAIRecord(spl(0), spl(1).toLong, spl(2).toLong, spl(3).toInt, spl(4).toInt)
    })
  }

  private def setPartialSequencePosition(record: FAIRecord): Unit = {
    /*
    A FAI record provides "bytes per line" and "bps per line".
    For example, if the latter is 61 but the former is 60, then 1 character per line of text is used for newlines.
    Here we calculate the bp position in the nucleotide sequence that this split will start at.
     */

    val seqStartPosition = startByte - record.start
    val row = seqStartPosition / record.bytesPerLine
    val posInLine = seqStartPosition % record.bytesPerLine

    val pos = if (posInLine >= record.bpsPerLine) {
      /*
      The position must be in the region where newline characters end up, so we consider
      ourselves to be on the next line. The position will apply to the next valid nucleotide character after trimming
      whitespace.
       */
      (row + 1) * record.bpsPerLine
    } else {
      //The position is within the normal sequence
      row * record.bpsPerLine + posInLine
    }
    //Convert from 0-based to 1-based sequence position
    currValue.setSeqPosition(pos + 1)
  }

  override def initialize(genericSplit: InputSplit, context: TaskAttemptContext): Unit = {
    val job = context.getConfiguration

    //Used to ensure we read full k-mers (we aim to read k-1 nucleotides from the next split when needed for a
    //partial sequence)
    k = context.getConfiguration.getInt("k", 10)

    val split = genericSplit.asInstanceOf[FileSplit]
    val path = split.getPath
    startByte = split.getStart
    endByte = startByte + split.getLength - 1
    val inputFile = path.getFileSystem(job).open(path)

    val faiPath = new Path(path.toString + ".fai")
    faiRecords = readFastaIndex(faiPath, job)

    //Keep only those FAI records that correspond to sequences in this split
    faiRecords = faiRecords.
      dropWhile(_.end < startByte).takeWhile(_.start <= endByte)

    val inputSplitSize = split.getLength.toInt
    val additionalBytes = k + 2

    //The entire split is read immediately
    myInputSplitBuffer = new Array[Byte](inputSplitSize + additionalBytes)

    sizeBuffer1 = inputFile.read(startByte, myInputSplitBuffer, 0, inputSplitSize)

    if (sizeBuffer1 <= 0) {
      return
    }

    //Additional characters from the next split
    sizeBuffer2 = inputFile.read(startByte + sizeBuffer1, myInputSplitBuffer, sizeBuffer1, additionalBytes)
    inputFile.close()
  }

  private def safeSetBytesToProcess(kmers: Int): Unit = {
    if (kmers < 0) {
      currValue.setBytesToProcess(0)
    } else {
      currValue.setBytesToProcess(kmers)
    }
  }

  override def nextKeyValue(): Boolean = {
    if (!faiRecords.hasNext || sizeBuffer1 <= 0) return false

    val record = faiRecords.next()

    currKey = new Text(record.id)
    currValue = new PartialSequence
    currValue.setHeader(record.id)
    currValue.setBuffer(myInputSplitBuffer)
    if (record.start >= startByte && record.end <= endByte) {
      //Read the sequence in full
      currValue.setSeqPosition(1)
      currValue.setComplete(true)
      currValue.setStartValue((record.start - startByte).toInt)
      currValue.setEndValue((record.end - startByte).toInt)
      //Number of k-mers (and newlines) in the value
      safeSetBytesToProcess((record.end - record.start + 1 - (k - 1)).toInt)
    } else {
      //Read partial
      if (record.start >= startByte) {
        //Started in this split
        currValue.setSeqPosition(1)
        //Skips the sequence header
        currValue.setStartValue((record.start - startByte).toInt)
      } else {
        //Started previously
        setPartialSequencePosition(record)
        currValue.setStartValue(0)
      }
      if (record.end <= endByte) {
        //Sequence ends in this split
        //Excess newline characters at the end will be automatically trimmed
        currValue.setEndValue((record.end - startByte).toInt)
        safeSetBytesToProcess(currValue.getEndValue - currValue.getStartValue + 1 - (k - 1))
      } else {
        //Sequence reaches into next split
        currValue.setEndValue(sizeBuffer1 + sizeBuffer2 - 1)
        //Number of k-mers (mixed with newlines) in the value
        safeSetBytesToProcess(sizeBuffer1 - currValue.getStartValue)

        //If the extra part in the next split was shorter than k - 1, we have to reduce accordingly
        if (sizeBuffer2 < (k - 1)) currValue.setBytesToProcess(
          currValue.getBytesToProcess - ((k - 1) - sizeBuffer2))
      }
    }

    true
  }

  override def getCurrentKey: Text =
    currKey

  override def getCurrentValue: PartialSequence =
    currValue

  override def getProgress: Float =
    if (faiRecords.hasNext) 0 else 1

  override def close(): Unit = {
    //inputFile has already been closed
    faiSource.close()
  }
}
